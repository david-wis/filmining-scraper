{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1af99d39",
   "metadata": {},
   "source": [
    "# Sentence Embeddings Analysis for Movie ROI Prediction\n",
    "\n",
    "This notebook uses **transformer-based sentence embeddings** (BERT) to capture the semantic meaning of movie text fields.\n",
    "\n",
    "Unlike TF-IDF which focuses on word frequency, sentence embeddings:\n",
    "- Capture **semantic similarity** even with different words\n",
    "- Understand **context and narrative themes**\n",
    "- Enable **clustering by meaning** rather than just keywords\n",
    "- Detect **emotional and thematic patterns** that correlate with ROI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a7097c",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719c866d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (run once)\n",
    "# !pip install sentence-transformers scikit-learn scipy matplotlib seaborn pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fda36a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add project root to path\n",
    "project_root = os.path.abspath('..')\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from src.analysis import EmbeddingsAnalyzer, TextPreprocessor, MovieDataLoader\n",
    "from src.database.connection import DatabaseConnection\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "print(\"âœ“ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a84771",
   "metadata": {},
   "source": [
    "## 2. Load Movie Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25aabbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize database connection\n",
    "db = DatabaseConnection()\n",
    "engine = db.get_engine()\n",
    "\n",
    "# Load movies with text fields\n",
    "loader = MovieDataLoader(engine)\n",
    "df = loader.load_movies_with_text(min_budget=100000)\n",
    "\n",
    "print(f\"Loaded {len(df)} movies\")\n",
    "print(f\"Average ROI: {df['roi'].mean():.2f}\")\n",
    "print(f\"Median ROI: {df['roi'].median():.2f}\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e67c20",
   "metadata": {},
   "source": [
    "## 3. Preprocess Text\n",
    "\n",
    "Combine text fields with appropriate weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58688f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize preprocessor\n",
    "preprocessor = TextPreprocessor(\n",
    "    lowercase=True,\n",
    "    remove_punctuation=False,  # Keep punctuation for BERT\n",
    "    remove_numbers=False,\n",
    "    remove_stopwords=False,  # BERT uses context\n",
    "    lemmatize=False  # BERT handles morphology\n",
    ")\n",
    "\n",
    "# Prepare documents\n",
    "documents = preprocessor.prepare_movie_documents(\n",
    "    df,\n",
    "    title_weight=2,\n",
    "    overview_weight=3,\n",
    "    tagline_weight=2,\n",
    "    genres_weight=2,\n",
    "    keywords_weight=1\n",
    ")\n",
    "\n",
    "print(f\"Prepared {len(documents)} documents\")\n",
    "print(f\"\\nExample document (first 500 chars):\\n{documents[0][:500]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d60f5c",
   "metadata": {},
   "source": [
    "## 4. Generate Embeddings\n",
    "\n",
    "Using `all-MiniLM-L6-v2` model:\n",
    "- Fast and efficient (384 dimensions)\n",
    "- Good balance between quality and speed\n",
    "- Trained on 1B+ sentence pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00720b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize embeddings analyzer\n",
    "embeddings_analyzer = EmbeddingsAnalyzer(\n",
    "    model_name='all-MiniLM-L6-v2',  # Fast, 384 dimensions\n",
    "    # model_name='all-mpnet-base-v2',  # Alternative: Higher quality, 768 dimensions\n",
    "    device='cpu'  # Use CPU (change to 'cuda' if you have compatible GPU with CUDA 11.x or 12.x)\n",
    ")\n",
    "\n",
    "# Generate embeddings\n",
    "embeddings = embeddings_analyzer.encode(\n",
    "    documents,\n",
    "    batch_size=32,\n",
    "    show_progress=True\n",
    ")\n",
    "\n",
    "print(f\"\\nEmbeddings shape: {embeddings.shape}\")\n",
    "print(f\"Each movie is represented by a {embeddings.shape[1]}-dimensional vector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57362a91",
   "metadata": {},
   "source": [
    "## 5. Correlation Analysis: Which Embedding Dimensions Predict ROI?\n",
    "\n",
    "Analyze which dimensions of the embedding space correlate with ROI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878a38c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute correlations\n",
    "dim_correlations = embeddings_analyzer.correlate_embeddings_with_roi(\n",
    "    df['roi'],\n",
    "    method='spearman',\n",
    "    top_dims=30\n",
    ")\n",
    "\n",
    "print(\"Top 20 embedding dimensions correlated with ROI:\\n\")\n",
    "print(dim_correlations.head(20))\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "top_dims = dim_correlations.head(20)\n",
    "\n",
    "colors = ['green' if x > 0 else 'red' for x in top_dims['correlation']]\n",
    "ax.barh(range(len(top_dims)), top_dims['correlation'], color=colors, alpha=0.7)\n",
    "ax.set_yticks(range(len(top_dims)))\n",
    "ax.set_yticklabels([f\"Dim {d}\" for d in top_dims['dimension']])\n",
    "ax.set_xlabel('Correlation with ROI')\n",
    "ax.set_title('Top 20 Embedding Dimensions by ROI Correlation')\n",
    "ax.axvline(x=0, color='black', linestyle='--', linewidth=0.8)\n",
    "ax.invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c27fa8",
   "metadata": {},
   "source": [
    "## 6. Semantic Clustering\n",
    "\n",
    "Group movies by semantic similarity and analyze ROI patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2ecfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster movies into semantic groups\n",
    "n_clusters = 15\n",
    "cluster_labels = embeddings_analyzer.cluster_movies(\n",
    "    n_clusters=n_clusters,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Analyze ROI by cluster\n",
    "cluster_stats = embeddings_analyzer.analyze_roi_by_clusters(\n",
    "    df,\n",
    "    cluster_labels,\n",
    "    roi_column='roi'\n",
    ")\n",
    "\n",
    "print(f\"\\nROI Statistics by Semantic Cluster:\\n\")\n",
    "print(cluster_stats)\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "x = range(len(cluster_stats))\n",
    "ax.bar(x, cluster_stats['roi_mean'], alpha=0.7, label='Mean ROI')\n",
    "ax.errorbar(x, cluster_stats['roi_mean'], yerr=cluster_stats['roi_std'], \n",
    "            fmt='none', color='black', alpha=0.5, capsize=3)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([f\"C{i}\\n(n={cluster_stats.iloc[i]['n_movies']})\" \n",
    "                     for i in range(len(cluster_stats))])\n",
    "ax.set_ylabel('ROI')\n",
    "ax.set_title(f'Average ROI by Semantic Cluster ({n_clusters} clusters)')\n",
    "ax.axhline(y=df['roi'].mean(), color='red', linestyle='--', label='Overall Mean')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81036bfd",
   "metadata": {},
   "source": [
    "## 7. Find Representative Movies in Each Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353d4609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get representative movies (closest to cluster centroid)\n",
    "representatives = embeddings_analyzer.get_cluster_representative_movies(\n",
    "    df,\n",
    "    cluster_labels,\n",
    "    embeddings,\n",
    "    n_per_cluster=3\n",
    ")\n",
    "\n",
    "# Display representatives for top 5 clusters (by ROI)\n",
    "top_clusters = cluster_stats.head(5).index\n",
    "\n",
    "for cluster_id in top_clusters:\n",
    "    cluster_roi = cluster_stats.loc[cluster_id, 'roi_mean']\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Cluster {cluster_id} - Mean ROI: {cluster_roi:.2f}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    rep_movies = representatives[cluster_id]\n",
    "    for idx, row in rep_movies.iterrows():\n",
    "        print(f\"\\nðŸ“½ï¸  {row['title']} (ROI: {row['roi']:.2f})\")\n",
    "        print(f\"   Genres: {row.get('genres', 'N/A')}\")\n",
    "        if pd.notna(row.get('overview')):\n",
    "            print(f\"   Overview: {row['overview'][:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4eae50e",
   "metadata": {},
   "source": [
    "## 8. Visualize Clusters in 2D\n",
    "\n",
    "Use PCA to reduce embeddings to 2D for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3b4bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce to 2D using PCA\n",
    "embeddings_2d = embeddings_analyzer.reduce_dimensions(\n",
    "    n_components=2,\n",
    "    embeddings=embeddings\n",
    ")\n",
    "\n",
    "# Plot clusters\n",
    "fig = embeddings_analyzer.plot_clusters_2d(\n",
    "    embeddings_2d,\n",
    "    cluster_labels,\n",
    "    roi_values=df['roi'].values,\n",
    "    figsize=(16, 7)\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5103bcf2",
   "metadata": {},
   "source": [
    "## 9. Find Similar Movies (Semantic Search)\n",
    "\n",
    "Discover movies with similar semantic content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1e6cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a movie to find similar ones\n",
    "query_movie = \"The Dark Knight\"  # Change this to any movie in your dataset\n",
    "\n",
    "# Find index\n",
    "query_idx = df[df['title'].str.contains(query_movie, case=False, na=False)].index\n",
    "\n",
    "if len(query_idx) > 0:\n",
    "    query_idx = query_idx[0]\n",
    "    \n",
    "    print(f\"Query Movie: {df.iloc[query_idx]['title']}\")\n",
    "    print(f\"ROI: {df.iloc[query_idx]['roi']:.2f}\")\n",
    "    print(f\"Overview: {df.iloc[query_idx]['overview']}\\n\")\n",
    "    \n",
    "    # Find similar movies\n",
    "    similar_indices, similarities = embeddings_analyzer.find_similar_movies(\n",
    "        query_idx,\n",
    "        top_k=10\n",
    "    )\n",
    "    \n",
    "    print(\"\\nTop 10 Most Similar Movies:\\n\")\n",
    "    for i, (idx, sim) in enumerate(zip(similar_indices, similarities), 1):\n",
    "        movie = df.iloc[idx]\n",
    "        print(f\"{i}. {movie['title']} (Similarity: {sim:.3f}, ROI: {movie['roi']:.2f})\")\n",
    "        print(f\"   Genres: {movie.get('genres', 'N/A')}\")\n",
    "        if pd.notna(movie.get('overview')):\n",
    "            print(f\"   Overview: {movie['overview'][:150]}...\")\n",
    "        print()\n",
    "else:\n",
    "    print(f\"Movie '{query_movie}' not found in dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4deacc",
   "metadata": {},
   "source": [
    "## 10. Export Embeddings for ML Models\n",
    "\n",
    "Save embeddings to use as features in prediction models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705d9a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame with embeddings\n",
    "embedding_cols = [f'emb_{i}' for i in range(embeddings.shape[1])]\n",
    "df_embeddings = pd.DataFrame(embeddings, columns=embedding_cols)\n",
    "\n",
    "# Add movie info and ROI\n",
    "df_embeddings['movie_id'] = df['id'].values\n",
    "df_embeddings['title'] = df['title'].values\n",
    "df_embeddings['roi'] = df['roi'].values\n",
    "df_embeddings['cluster'] = cluster_labels\n",
    "\n",
    "# Save to CSV\n",
    "output_path = '../data/movie_embeddings.csv'\n",
    "df_embeddings.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"âœ“ Saved embeddings to {output_path}\")\n",
    "print(f\"  Shape: {df_embeddings.shape}\")\n",
    "print(f\"  Columns: {len(embedding_cols)} embedding dimensions + metadata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b272e3",
   "metadata": {},
   "source": [
    "## 11. Compare High vs Low ROI Movies Semantically\n",
    "\n",
    "Analyze semantic differences between successful and unsuccessful movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d66021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment by ROI quartiles\n",
    "roi_quartiles = df['roi'].quantile([0.25, 0.75])\n",
    "low_roi_mask = df['roi'] <= roi_quartiles[0.25]\n",
    "high_roi_mask = df['roi'] >= roi_quartiles[0.75]\n",
    "\n",
    "print(f\"Low ROI threshold: {roi_quartiles[0.25]:.2f}\")\n",
    "print(f\"High ROI threshold: {roi_quartiles[0.75]:.2f}\")\n",
    "print(f\"\\nLow ROI movies: {low_roi_mask.sum()}\")\n",
    "print(f\"High ROI movies: {high_roi_mask.sum()}\")\n",
    "\n",
    "# Compute average embeddings for each segment\n",
    "low_roi_centroid = embeddings[low_roi_mask].mean(axis=0)\n",
    "high_roi_centroid = embeddings[high_roi_mask].mean(axis=0)\n",
    "\n",
    "# Compute semantic distance\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "semantic_similarity = cosine_similarity(\n",
    "    low_roi_centroid.reshape(1, -1),\n",
    "    high_roi_centroid.reshape(1, -1)\n",
    ")[0, 0]\n",
    "\n",
    "print(f\"\\nSemantic similarity between low and high ROI movies: {semantic_similarity:.3f}\")\n",
    "print(f\"Semantic distance: {1 - semantic_similarity:.3f}\")\n",
    "print(\"\\nðŸ’¡ Lower similarity = more semantic difference between segments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f291db7",
   "metadata": {},
   "source": [
    "## 12. Conclusions and Next Steps\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **Semantic Clusters**: Movies naturally group by themes/narratives\n",
    "2. **ROI Patterns**: Certain semantic clusters have higher average ROI\n",
    "3. **Predictive Dimensions**: Some embedding dimensions correlate with ROI\n",
    "\n",
    "### How Embeddings Improve ROI Prediction:\n",
    "\n",
    "- **Beyond Keywords**: Captures meaning, not just word occurrence\n",
    "- **Narrative Patterns**: Identifies story structures that resonate with audiences\n",
    "- **Genre-Crossing Themes**: Finds successful patterns across genres\n",
    "- **Contextual Understanding**: Understands emotional tone and themes\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. Use embeddings as features in ML models (Random Forest, XGBoost, Neural Networks)\n",
    "2. Combine with other features (budget, cast, runtime, etc.)\n",
    "3. Try different embedding models (mpnet, RoBERTa, etc.)\n",
    "4. Implement similarity-based prediction (predict ROI from similar movies)\n",
    "5. Analyze cluster-specific prediction models"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
