{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da253637",
   "metadata": {},
   "source": [
    "# üìù An√°lisis Sem√°ntico de Campos de Texto\n",
    "\n",
    "**Objetivo:** Analizar los campos de texto de las pel√≠culas para descubrir patrones ling√º√≠sticos y tem√°ticos que se correlacionen con el ROI.\n",
    "\n",
    "**Campos analizados:**\n",
    "- `title`: T√≠tulo de la pel√≠cula\n",
    "- `overview`: Sinopsis/descripci√≥n\n",
    "- `tagline`: Frase promocional\n",
    "- `genres`: G√©neros cinematogr√°ficos\n",
    "- `keywords`: Palabras clave\n",
    "\n",
    "**Metodolog√≠as:**\n",
    "1. **TF-IDF (Term Frequency-Inverse Document Frequency)**: Identifica t√©rminos distintivos\n",
    "2. **An√°lisis de correlaci√≥n**: Relaciona t√©rminos con ROI\n",
    "3. **Segmentaci√≥n por ROI**: Compara vocabulario entre pel√≠culas exitosas y no exitosas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952567d4",
   "metadata": {},
   "source": [
    "## 1. Instalaci√≥n de dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf04ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar dependencias necesarias para an√°lisis sem√°ntico\n",
    "%pip install scikit-learn scipy matplotlib seaborn pandas numpy sqlalchemy psycopg2-binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d743ca",
   "metadata": {},
   "source": [
    "## 2. Imports y configuraci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a291d21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports est√°ndar\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "# Configuraci√≥n\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Importar m√≥dulos de an√°lisis sem√°ntico\n",
    "import sys\n",
    "sys.path.append('/mnt/SSD_DATA/jonyloco/itba/DS/filmining-scraper')\n",
    "\n",
    "from src.analysis import TextPreprocessor, TFIDFAnalyzer, MovieDataLoader\n",
    "\n",
    "print(\"‚úì Imports completados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9106014b",
   "metadata": {},
   "source": [
    "## 3. Carga y preparaci√≥n de datos\n",
    "\n",
    "Se cargan las pel√≠culas con sus campos de texto y datos financieros v√°lidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31a9d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== CARGA DE DATOS PARA AN√ÅLISIS SEM√ÅNTICO ===\")\n",
    "\n",
    "# Conectar a la base de datos\n",
    "loader = MovieDataLoader('postgresql://postgres:postgres@localhost:25432/movie_database')\n",
    "\n",
    "# Cargar pel√≠culas con text fields y datos financieros v√°lidos\n",
    "df_text = loader.load_movies_with_text(\n",
    "    min_budget=100000,  # Filtrar datos mal cargados\n",
    "    include_genres=True,\n",
    "    include_keywords=True\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úì Pel√≠culas cargadas: {len(df_text):,}\")\n",
    "print(f\"‚úì ROI promedio: {df_text['roi'].mean():.3f}\")\n",
    "print(f\"‚úì ROI mediano: {df_text['roi'].median():.3f}\")\n",
    "\n",
    "df_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e127e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estad√≠sticas de campos de texto\n",
    "print(\"\\n=== ESTAD√çSTICAS DE CAMPOS DE TEXTO ===\")\n",
    "\n",
    "for field in ['title', 'overview', 'tagline', 'genres', 'keywords']:\n",
    "    if field in df_text.columns:\n",
    "        non_empty = df_text[field].notna().sum()\n",
    "        pct = (non_empty / len(df_text)) * 100\n",
    "        print(f\"{field:12s}: {non_empty:5,} ({pct:5.1f}%) registros no vac√≠os\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a2248e",
   "metadata": {},
   "source": [
    "## 4. Preprocesamiento de texto\n",
    "\n",
    "Se combinan todos los campos de texto en un \"documento\" por pel√≠cula, aplicando:\n",
    "- Limpieza de texto (min√∫sculas, puntuaci√≥n, etc.)\n",
    "- Ponderaci√≥n de campos (el t√≠tulo se repite para darle m√°s peso)\n",
    "- Filtrado de palabras cortas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecd3a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== PREPROCESAMIENTO DE TEXTO ===\")\n",
    "\n",
    "# Inicializar preprocesador\n",
    "preprocessor = TextPreprocessor(\n",
    "    lowercase=True,\n",
    "    remove_punctuation=True,\n",
    "    remove_numbers=False,\n",
    "    min_word_length=2\n",
    ")\n",
    "\n",
    "# Preparar documentos combinando todos los campos de texto\n",
    "df_documents = preprocessor.prepare_movie_documents(\n",
    "    df_text,\n",
    "    include_title=True,\n",
    "    include_overview=True,\n",
    "    include_tagline=True,\n",
    "    include_genres=True,\n",
    "    include_keywords=True,\n",
    "    title_weight=2,  # El t√≠tulo se repite 2 veces\n",
    "    tagline_weight=1\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úì Documentos preparados: {len(df_documents):,}\")\n",
    "print(f\"‚úì Longitud promedio: {df_documents['document'].str.len().mean():.0f} caracteres\")\n",
    "print(f\"‚úì Palabras promedio: {df_documents['document'].str.split().str.len().mean():.0f} palabras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d1f993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar ejemplo de documento procesado\n",
    "print(\"\\n=== EJEMPLO DE DOCUMENTO PROCESADO ===\")\n",
    "\n",
    "sample_idx = df_documents['roi'].idxmax()  # Pel√≠cula con mayor ROI\n",
    "print(f\"Pel√≠cula: {df_documents.loc[sample_idx, 'title']}\")\n",
    "print(f\"ROI: {df_documents.loc[sample_idx, 'roi']:.2f}\")\n",
    "print(f\"\\nDocumento procesado:\")\n",
    "print(df_documents.loc[sample_idx, 'document'][:500] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a471c3",
   "metadata": {},
   "source": [
    "## 5. An√°lisis TF-IDF\n",
    "\n",
    "**TF-IDF (Term Frequency-Inverse Document Frequency)** identifica t√©rminos importantes en cada documento.\n",
    "\n",
    "- **TF (Term Frequency)**: Frecuencia del t√©rmino en el documento\n",
    "- **IDF (Inverse Document Frequency)**: Qu√© tan √∫nico es el t√©rmino en todo el corpus\n",
    "\n",
    "Los t√©rminos con alto TF-IDF son frecuentes en un documento espec√≠fico pero raros en el resto, lo que los hace **distintivos**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cc1af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== AN√ÅLISIS TF-IDF ===\")\n",
    "\n",
    "# Crear y ajustar analizador TF-IDF\n",
    "tfidf = TFIDFAnalyzer(\n",
    "    max_features=500,      # M√°ximo 500 t√©rminos\n",
    "    min_df=5,              # T√©rmino debe aparecer en al menos 5 pel√≠culas\n",
    "    max_df=0.8,            # T√©rmino no debe aparecer en m√°s del 80% de pel√≠culas\n",
    "    ngram_range=(1, 2),    # Unigramas y bigramas\n",
    "    use_idf=True,\n",
    "    sublinear_tf=True      # Escala logar√≠tmica para TF\n",
    ")\n",
    "\n",
    "# Ajustar TF-IDF\n",
    "tfidf_matrix = tfidf.fit_transform(df_documents['document'])\n",
    "\n",
    "print(f\"\\n‚úì Matriz TF-IDF shape: {tfidf_matrix.shape}\")\n",
    "print(f\"‚úì Sparsity: {(1 - tfidf_matrix.nnz / (tfidf_matrix.shape[0] * tfidf_matrix.shape[1])) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07084715",
   "metadata": {},
   "source": [
    "### 5.1 T√©rminos m√°s importantes globalmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af09e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T√©rminos m√°s importantes globalmente\n",
    "print(\"=== T√âRMINOS M√ÅS IMPORTANTES GLOBALMENTE ===\")\n",
    "\n",
    "top_terms_global = tfidf.get_top_terms_global(top_n=30)\n",
    "print(top_terms_global.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98117a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar t√©rminos globales\n",
    "tfidf.plot_top_terms(top_n=25, figsize=(14, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a35d7b",
   "metadata": {},
   "source": [
    "### 5.2 Correlaci√≥n entre t√©rminos y ROI\n",
    "\n",
    "Se analiza qu√© t√©rminos est√°n m√°s correlacionados con el ROI:\n",
    "- **Correlaci√≥n positiva**: T√©rminos que aparecen m√°s en pel√≠culas rentables\n",
    "- **Correlaci√≥n negativa**: T√©rminos que aparecen m√°s en pel√≠culas no rentables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14ebc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== CORRELACI√ìN DE T√âRMINOS CON ROI ===\")\n",
    "\n",
    "# Asegurar que los √≠ndices coincidan\n",
    "roi_values = df_documents.loc[df_documents.index, 'roi']\n",
    "\n",
    "# Calcular correlaciones (Spearman es m√°s robusto a outliers)\n",
    "correlations = tfidf.correlate_with_target(\n",
    "    roi_values,\n",
    "    method='spearman',\n",
    "    top_n=40\n",
    ")\n",
    "\n",
    "print(\"\\nTop 20 t√©rminos m√°s correlacionados con ROI:\")\n",
    "print(correlations.head(20).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dde794c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar correlaciones\n",
    "tfidf.plot_correlation_with_roi(\n",
    "    roi_values,\n",
    "    top_n=15,\n",
    "    method='spearman',\n",
    "    figsize=(16, 8)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a17c54a",
   "metadata": {},
   "source": [
    "### 5.3 An√°lisis por segmentos de ROI\n",
    "\n",
    "Se divide el dataset en cuartiles seg√∫n ROI y se analizan los t√©rminos m√°s caracter√≠sticos de cada segmento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bac3245",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== AN√ÅLISIS POR SEGMENTOS DE ROI ===\")\n",
    "\n",
    "segments_results = tfidf.analyze_roi_segments(\n",
    "    df_documents,\n",
    "    roi_column='roi',\n",
    "    n_segments=4,\n",
    "    top_terms_per_segment=15\n",
    ")\n",
    "\n",
    "# Mostrar resultados por segmento\n",
    "for segment_name, segment_df in sorted(segments_results.items()):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"SEGMENTO: {segment_name}\")\n",
    "    print('='*60)\n",
    "    print(segment_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce6c51a",
   "metadata": {},
   "source": [
    "### 5.4 Comparaci√≥n: Alto ROI vs Bajo ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839cc99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaci√≥n visual de vocabulario\n",
    "print(\"=== COMPARACI√ìN: ALTO ROI vs BAJO ROI ===\")\n",
    "\n",
    "# Dividir en dos grupos: top 25% y bottom 25%\n",
    "roi_q75 = df_documents['roi'].quantile(0.75)\n",
    "roi_q25 = df_documents['roi'].quantile(0.25)\n",
    "\n",
    "high_roi_mask = df_documents['roi'] >= roi_q75\n",
    "low_roi_mask = df_documents['roi'] <= roi_q25\n",
    "\n",
    "print(f\"Pel√≠culas con ALTO ROI (>= {roi_q75:.2f}): {high_roi_mask.sum()}\")\n",
    "print(f\"Pel√≠culas con BAJO ROI (<= {roi_q25:.2f}): {low_roi_mask.sum()}\")\n",
    "\n",
    "# Gr√°fico comparativo\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8))\n",
    "\n",
    "# Top t√©rminos en pel√≠culas de alto ROI\n",
    "if 'Q4' in segments_results:\n",
    "    high_roi_terms = segments_results['Q4'].head(15)\n",
    "    ax1.barh(range(len(high_roi_terms)), high_roi_terms['mean_tfidf'], color='green', alpha=0.7)\n",
    "    ax1.set_yticks(range(len(high_roi_terms)))\n",
    "    ax1.set_yticklabels(high_roi_terms['term'])\n",
    "    ax1.set_xlabel('Mean TF-IDF Score')\n",
    "    ax1.set_title('Top T√©rminos en Pel√≠culas de ALTO ROI (Q4)', fontweight='bold', fontsize=12)\n",
    "    ax1.invert_yaxis()\n",
    "\n",
    "# Top t√©rminos en pel√≠culas de bajo ROI\n",
    "if 'Q1' in segments_results:\n",
    "    low_roi_terms = segments_results['Q1'].head(15)\n",
    "    ax2.barh(range(len(low_roi_terms)), low_roi_terms['mean_tfidf'], color='red', alpha=0.7)\n",
    "    ax2.set_yticks(range(len(low_roi_terms)))\n",
    "    ax2.set_yticklabels(low_roi_terms['term'])\n",
    "    ax2.set_xlabel('Mean TF-IDF Score')\n",
    "    ax2.set_title('Top T√©rminos en Pel√≠culas de BAJO ROI (Q1)', fontweight='bold', fontsize=12)\n",
    "    ax2.invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6606d9c1",
   "metadata": {},
   "source": [
    "### 5.5 Reducci√≥n de dimensionalidad (SVD)\n",
    "\n",
    "Se aplica SVD (Singular Value Decomposition) para reducir la dimensionalidad de la matriz TF-IDF y crear features compactas para modelos predictivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7681b7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== REDUCCI√ìN DE DIMENSIONALIDAD CON SVD ===\")\n",
    "\n",
    "reduced_features = tfidf.apply_dimensionality_reduction(n_components=50)\n",
    "\n",
    "print(f\"\\n‚úì Features reducidas shape: {reduced_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a528dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar varianza explicada\n",
    "explained_var = tfidf.svd_model.explained_variance_ratio_\n",
    "cumulative_var = np.cumsum(explained_var)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Varianza por componente\n",
    "ax1.bar(range(len(explained_var)), explained_var, alpha=0.7)\n",
    "ax1.set_xlabel('Componente')\n",
    "ax1.set_ylabel('Varianza explicada')\n",
    "ax1.set_title('Varianza explicada por componente SVD')\n",
    "\n",
    "# Varianza acumulada\n",
    "ax2.plot(range(len(cumulative_var)), cumulative_var, marker='o', linewidth=2)\n",
    "ax2.axhline(y=0.8, color='r', linestyle='--', label='80% varianza')\n",
    "ax2.axhline(y=0.9, color='g', linestyle='--', label='90% varianza')\n",
    "ax2.set_xlabel('N√∫mero de componentes')\n",
    "ax2.set_ylabel('Varianza explicada acumulada')\n",
    "ax2.set_title('Varianza acumulada')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Encontrar cu√°ntos componentes necesitamos para 80% y 90%\n",
    "n_80 = np.argmax(cumulative_var >= 0.8) + 1\n",
    "n_90 = np.argmax(cumulative_var >= 0.9) + 1\n",
    "print(f\"\\nComponentes necesarios para 80% varianza: {n_80}\")\n",
    "print(f\"Componentes necesarios para 90% varianza: {n_90}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5187569e",
   "metadata": {},
   "source": [
    "## 6. Exportar features para modelado\n",
    "\n",
    "Se pueden exportar las features TF-IDF o las reducidas con SVD para usarlas en modelos predictivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e86cbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear DataFrame con features TF-IDF reducidas\n",
    "feature_columns = [f'tfidf_svd_{i}' for i in range(reduced_features.shape[1])]\n",
    "df_tfidf_features = pd.DataFrame(\n",
    "    reduced_features,\n",
    "    index=df_documents.index,\n",
    "    columns=feature_columns\n",
    ")\n",
    "\n",
    "# Combinar con datos originales\n",
    "df_for_modeling = df_documents[['id', 'title', 'roi', 'budget', 'revenue']].copy()\n",
    "df_for_modeling = pd.concat([df_for_modeling, df_tfidf_features], axis=1)\n",
    "\n",
    "print(f\"‚úì DataFrame para modelado: {df_for_modeling.shape}\")\n",
    "df_for_modeling.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d20054",
   "metadata": {},
   "source": [
    "## 7. Resumen y conclusiones\n",
    "\n",
    "### Hallazgos principales:\n",
    "\n",
    "**1. T√©rminos globalmente importantes:**\n",
    "- Los t√©rminos con mayor TF-IDF representan conceptos distintivos en el corpus\n",
    "- Revelan los temas y g√©neros m√°s representados en el dataset\n",
    "\n",
    "**2. Relaci√≥n con ROI:**\n",
    "- Se identificaron t√©rminos con correlaci√≥n significativa con ROI\n",
    "- **Correlaciones positivas**: T√©rminos que aparecen m√°s en pel√≠culas rentables\n",
    "- **Correlaciones negativas**: T√©rminos que aparecen m√°s en pel√≠culas no rentables\n",
    "- La correlaci√≥n sugiere patrones pero no implica causalidad\n",
    "\n",
    "**3. Diferencias por segmento:**\n",
    "- Pel√≠culas de alto ROI (Q4) tienen vocabulario caracter√≠stico diferente al de bajo ROI (Q1)\n",
    "- Los t√©rminos distintivos pueden reflejar:\n",
    "  - G√©neros m√°s rentables\n",
    "  - Temas narrativos exitosos\n",
    "  - Keywords de marketing efectivas\n",
    "\n",
    "**4. Aplicabilidad:**\n",
    "- Las features TF-IDF pueden usarse en modelos predictivos de ROI\n",
    "- La reducci√≥n con SVD permite trabajar con features m√°s compactas\n",
    "- 50 componentes SVD capturan la mayor parte de la varianza del texto\n",
    "\n",
    "### Limitaciones:\n",
    "\n",
    "1. **TF-IDF no captura sem√°ntica**: \"king\" y \"queen\" son tratados como completamente independientes\n",
    "2. **Sensible a preprocesamiento**: La limpieza de texto afecta significativamente los resultados\n",
    "3. **Correlaci√≥n ‚â† Causalidad**: Los t√©rminos correlacionados pueden ser s√≠ntomas, no causas del √©xito\n",
    "\n",
    "### Pr√≥ximos pasos sugeridos:\n",
    "\n",
    "1. **Sentence Embeddings (BERT, Sentence-BERT)**: Para capturar sem√°ntica profunda\n",
    "2. **Topic Modeling (LDA)**: Para descubrir temas latentes\n",
    "3. **Sentiment Analysis**: En overview y tagline\n",
    "4. **Integraci√≥n en modelos**: Usar features TF-IDF en modelos de ML para predecir ROI"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
